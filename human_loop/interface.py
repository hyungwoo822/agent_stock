# human_loop/interface.py
from typing import Dict, List, Optional
from datetime import datetime
import asyncio
from queue import Queue
import json
import uuid
import logging

logger = logging.getLogger(__name__)

class HumanInTheLoop:
    """Human-in-the-loop ì¸í„°íŽ˜ì´ìŠ¤"""
    
    def __init__(self):
        self.feedback_queue = Queue()
        self.decision_history = []
        self.learning_data = []
        self.approval_patterns = {}
        
    async def request_review(self, decision_context: Dict) -> Dict:
        """ì‚¬ìš©ìž ë¦¬ë·° ìš”ì²­"""
        review_request = {
            "id": str(uuid.uuid4()),
            "timestamp": datetime.now().isoformat(),
            "context": decision_context,
            "proposed_actions": decision_context.get("decisions", []),
            "risk_analysis": decision_context.get("risk_assessment", {}),
            "market_conditions": decision_context.get("market_sentiment", "neutral"),
            "estimated_impact": self._calculate_impact(decision_context)
        }
        
        # ì‚¬ìš©ìžì—ê²Œ ë¦¬ë·° ìš”ì²­ ì „ì†¡
        response = await self._send_to_user(review_request)
        
        # í”¼ë“œë°± ì €ìž¥ ë° í•™ìŠµ
        self._store_feedback(response)
        self._learn_from_feedback(response)
        
        return response
    
    async def _send_to_user(self, review_request: Dict) -> Dict:
        """ì‚¬ìš©ìžì—ê²Œ ë¦¬ë·° ìš”ì²­ ì „ì†¡"""
        # ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” ì›¹ì†Œì¼“, ì´ë©”ì¼, ì•± ì•Œë¦¼ ë“± ì‚¬ìš©
        
        print("\n" + "="*50)
        print("ðŸ”” HUMAN REVIEW REQUESTED")
        print("="*50)
        
        print(f"\nðŸ“Š Market Sentiment: {review_request['market_conditions']}")
        print(f"âš ï¸  Risk Level: {review_request['risk_analysis'].get('risk_level', 'N/A')}")
        print(f"ðŸ’° Estimated Impact: ${review_request['estimated_impact']:.2f}")
        
        print("\nðŸ“‹ Proposed Actions:")
        for i, action in enumerate(review_request['proposed_actions'], 1):
            print(f"  {i}. {action['action']} {action.get('quantity', 'N/A')} shares of {action['ticker']} at ${action.get('limit_price', 'N/A')}")
        
        print("\n" + "-"*50)
        
        # ì‹œë®¬ë ˆì´ì…˜ì„ ìœ„í•œ ìžë™ ìŠ¹ì¸ (ì‹¤ì œë¡œëŠ” ì‚¬ìš©ìž ìž…ë ¥ ëŒ€ê¸°)
        await asyncio.sleep(2)  # ì‚¬ìš©ìž ê²€í†  ì‹œê°„ ì‹œë®¬ë ˆì´ì…˜
        
        # ì‚¬ìš©ìž ì‘ë‹µ ì‹œë®¬ë ˆì´ì…˜
        response = {
            "request_id": review_request["id"],
            "approved": True,  # ë˜ëŠ” ì‚¬ìš©ìž ìž…ë ¥ì— ë”°ë¼
            "modified_decisions": review_request["proposed_actions"],
            "user_comments": "Looks good, proceed with caution on tech stocks",
            "response_time": datetime.now().isoformat(),
            "confidence_level": 0.8
        }
        
        print(f"\nâœ… User Response: {'APPROVED' if response['approved'] else 'MODIFIED'}")
        if response.get('user_comments'):
            print(f"ðŸ’¬ Comments: {response['user_comments']}")
        print("="*50 + "\n")
        
        return response
    
    def _calculate_impact(self, context: Dict) -> float:
        """ì˜ˆìƒ ì˜í–¥ ê³„ì‚°"""
        total_value = 0
        
        for decision in context.get("decisions", []):
            value = decision.get("quantity", 0) * decision.get("limit_price", 0)
            total_value += value
        
        return total_value
    
    def _store_feedback(self, feedback: Dict):
        """í”¼ë“œë°± ì €ìž¥"""
        self.decision_history.append({
            "timestamp": datetime.now().isoformat(),
            "feedback": feedback,
            "outcome": None  # ë‚˜ì¤‘ì— ê²°ê³¼ ì—…ë°ì´íŠ¸
        })
        
        # í”¼ë“œë°±ì„ íì— ì¶”ê°€
        self.feedback_queue.put(feedback)
    
    def _learn_from_feedback(self, feedback: Dict):
        """í”¼ë“œë°±ìœ¼ë¡œë¶€í„° í•™ìŠµ"""
        # ìŠ¹ì¸ íŒ¨í„´ í•™ìŠµ
        if feedback.get("approved"):
            # ìŠ¹ì¸ëœ ê²°ì •ì˜ íŠ¹ì§• ì €ìž¥
            for decision in feedback.get("modified_decisions", []):
                key = f"{decision['action']}_{decision['ticker']}"
                
                if key not in self.approval_patterns:
                    self.approval_patterns[key] = {
                        "approved_count": 0,
                        "rejected_count": 0,
                        "avg_confidence": 0
                    }
                
                self.approval_patterns[key]["approved_count"] += 1
                self.approval_patterns[key]["avg_confidence"] = (
                    self.approval_patterns[key]["avg_confidence"] * 0.9 +
                    feedback.get("confidence_level", 0.5) * 0.1
                )
        else:
            # ê±°ë¶€ëœ ê²°ì • íŒ¨í„´ í•™ìŠµ
            for decision in feedback.get("modified_decisions", []):
                key = f"{decision['action']}_{decision['ticker']}"
                
                if key not in self.approval_patterns:
                    self.approval_patterns[key] = {
                        "approved_count": 0,
                        "rejected_count": 0,
                        "avg_confidence": 0
                    }
                
                self.approval_patterns[key]["rejected_count"] += 1
        
        # í•™ìŠµ ë°ì´í„° ì €ìž¥
        self.learning_data.append({
            "timestamp": datetime.now().isoformat(),
            "feedback": feedback,
            "patterns": dict(self.approval_patterns)
        })
    
    def get_approval_likelihood(self, decision: Dict) -> float:
        """ê²°ì •ì˜ ìŠ¹ì¸ ê°€ëŠ¥ì„± ì˜ˆì¸¡"""
        key = f"{decision['action']}_{decision['ticker']}"
        
        if key in self.approval_patterns:
            pattern = self.approval_patterns[key]
            total = pattern["approved_count"] + pattern["rejected_count"]
            
            if total > 0:
                return pattern["approved_count"] / total
        
        return 0.5  # ê¸°ë³¸ê°’
    
    def update_outcome(self, request_id: str, outcome: Dict):
        """ê²°ê³¼ ì—…ë°ì´íŠ¸"""
        for record in self.decision_history:
            if record.get("feedback", {}).get("request_id") == request_id:
                record["outcome"] = outcome
                
                # ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì¶”ê°€ í•™ìŠµ
                if outcome.get("profit_loss", 0) > 0:
                    # ìˆ˜ìµì´ ë‚œ ê²°ì • ê°•í™”
                    self._reinforce_positive_pattern(record["feedback"])
                else:
                    # ì†ì‹¤ì´ ë‚œ ê²°ì • ì•½í™”
                    self._reinforce_negative_pattern(record["feedback"])
                
                break
    
    def _reinforce_positive_pattern(self, feedback: Dict):
        """ê¸ì •ì  íŒ¨í„´ ê°•í™”"""
        for decision in feedback.get("modified_decisions", []):
            key = f"{decision['action']}_{decision['ticker']}"
            
            if key in self.approval_patterns:
                self.approval_patterns[key]["avg_confidence"] = min(
                    1.0,
                    self.approval_patterns[key]["avg_confidence"] * 1.1
                )
    
    def _reinforce_negative_pattern(self, feedback: Dict):
        """ë¶€ì •ì  íŒ¨í„´ ì•½í™”"""
        for decision in feedback.get("modified_decisions", []):
            key = f"{decision['action']}_{decision['ticker']}"
            
            if key in self.approval_patterns:
                self.approval_patterns[key]["avg_confidence"] = max(
                    0.0,
                    self.approval_patterns[key]["avg_confidence"] * 0.9
                )
    
    def get_learning_summary(self) -> Dict:
        """í•™ìŠµ ìš”ì•½ ë°˜í™˜"""
        total_decisions = len(self.decision_history)
        approved_decisions = sum(
            1 for d in self.decision_history 
            if d.get("feedback", {}).get("approved")
        )
        
        profitable_outcomes = sum(
            1 for d in self.decision_history
            if d.get("outcome", {}).get("profit_loss", 0) > 0
        )
        
        return {
            "total_decisions_reviewed": total_decisions,
            "approval_rate": approved_decisions / total_decisions if total_decisions > 0 else 0,
            "profitable_rate": profitable_outcomes / total_decisions if total_decisions > 0 else 0,
            "top_approved_patterns": sorted(
                self.approval_patterns.items(),
                key=lambda x: x[1]["approved_count"],
                reverse=True
            )[:5],
            "learning_metrics": {
                "patterns_learned": len(self.approval_patterns),
                "avg_confidence": np.mean([
                    p["avg_confidence"] 
                    for p in self.approval_patterns.values()
                ]) if self.approval_patterns else 0
            }
        }